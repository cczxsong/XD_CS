### 关联规则挖掘  美国国会投票记录

------

#### **一、实验内容**

关联规则挖掘，使用Apriori算法，支持度设为30%，置信度为90%，挖掘高置信度的规则

数据来源：http://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records

#### 二、分析及设计

1、数据预处理

2、scan数据集，创建C1，根据最小支持度从C1中删除不满足的项，从而获得频繁1项集L1 

3、对L2的自身连接生成的集合执行剪枝策略产生候选3项集的集合C3，然后，扫描所有事务，对C3每个项进行计数。同样的，根据最小支持度从C3中删除不满足的项，从而获得频繁3项集L3 

4、以此类推，获得K项集

5、输出规则

#### **三、详细实现**

1、数据预处理

通过对CQA和数据集的数据进行拼接，得到每条记录的具体信息

```python
def prepare_data(file):
    CQA = ["Class-Name", "handicapped-infants", "water-project-cost-sharing", "adoption-of-the-budget-resolution",
           "physician-fee-freeze", "el-salvador-aid", "religious-groups-in-schools", "anti-satellite-test-ban",
           "aid-to-nicaraguan-contras", "mx-missile", "immigration", "synfuels-corporation-cutback",
           "education-spending",
           "superfund-right-to-sue", "crime", "duty-free-exports", "export-administration-act-south-africa"]
    dataset = [x.strip().split(',') for x in open(file)]
    new_dataset = []
    for data in dataset:
        new_data = set()
        for i, x in enumerate(data):
            new_data.add(CQA[i] + "_" + x)
        # print new_data
        new_dataset.append(new_data)
    f = open('new-house-votes.data', 'w')
    for t in new_dataset:
        f.write(','.join(str(x) for x in t) + '\n')
    f.close()
```

2、创建C1

```python
def create_C1(data_set):
    C1 = set()
    for t in data_set:
        for item in t:
            item_set = frozenset([item])
            C1.add(item_set)
    return C1
```

3、剪枝

任何非频繁的(k-1)项集都不是频繁k项集的子集

```python
def is_apriori(Ck_item, Lksub1):
    for item in Ck_item:
        sub_Ck = Ck_item - frozenset([item])
        if sub_Ck not in Lksub1:
            return False
    return True
```

4、由Lk-1生成Ck（具体实现方法是在Lk-1中，对所有两个项集之间只有最后一项item不同的项集的交集）

```
def create_Ck(Lksub1, k):
    Ck = set()
    len_Lksub1 = len(Lksub1)
    list_Lksub1 = list(Lksub1)
    for i in range(len_Lksub1):
        for j in range(1, len_Lksub1):
            l1 = list(list_Lksub1[i])
            l2 = list(list_Lksub1[j])
            l1.sort()
            l2.sort()
            if l1[0:k - 2] == l2[0:k - 2]:
                Ck_item = list_Lksub1[i] | list_Lksub1[j]
                if is_apriori(Ck_item, Lksub1):
                    Ck.add(Ck_item)
    return Ck
```

5、由候选频繁k项集Ck生成频繁k项集Lk
        主要内容是对Ck中的每个项集计算支持度，去掉不满足最低支持度的项集
        返回Lk，记录support_data

```python
def generate_Lk_by_Ck(data_set, Ck, min_support, support_data):
    Lk = set()
    item_count = {}
    for t in data_set:  
        for item in Ck:  
            if item.issubset(t):  
                if item not in item_count:  #
                    item_count[item] = 1
                else:  
                    item_count[item] += 1
    t_num = float(len(data_set)) 
    for item in item_count:  
        if (item_count[item] / t_num) >= min_support:
            Lk.add(item)  # 满足最小支持度的项集add进频繁项集Lk中
            support_data[item] = item_count[item] / t_num  
    return Lk
```

6、生成频繁集Lk，通过调用generate_Lk_by_Ck
        从C1开始共进行k轮迭代，将每次生成的Lk都append到L中，同时记录支持度support_data

```python
def generate_L(data_set, k, min_support):
    support_data = {}
    C1 = create_C1(data_set)  # 生成C1
    L1 = generate_Lk_by_Ck(data_set, C1, min_support, support_data)  #生成L1
    Lksub1 = L1.copy()
    L = []
    L.append(Lksub1)
    for i in range(2, k + 1): 
        Ci = create_Ck(Lksub1, i)  
        Li = generate_Lk_by_Ck(data_set, Ci, min_support, support_data)
        Lksub1 = Li.copy()
        L.append(Lksub1)
    return L, support_data
```

7、输出

对规则进行筛选输出


